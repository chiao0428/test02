{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "ResNet152.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiao0428/test02/blob/main/ResNet152(pytorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZFpf1dv8b4i",
        "outputId": "2b553e21-8773-457e-daed-36cf5c06f7dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "9ZFpf1dv8b4i",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "patient-asbestos"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "patient-asbestos",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "double-raleigh",
        "outputId": "10a02839-cf81-4091-df3b-d74a51c5db20"
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
        "print(device)"
      ],
      "id": "double-raleigh",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opponent-shoot"
      },
      "source": [
        "class basic_block(nn.Module):\n",
        "    # 輸出通道乘的倍數\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride, downsample):\n",
        "        super(basic_block, self).__init__()      \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 在 shortcut 時，若維度不一樣，要更改維度\n",
        "        self.downsample = downsample \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "id": "opponent-shoot",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "directed-terry"
      },
      "source": [
        "class bottleneck_block(nn.Module):\n",
        "    # 輸出通道乘的倍數\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride, downsample):\n",
        "        super(bottleneck_block, self).__init__()      \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        # 在 shortcut 時，若維度不一樣，要更改維度\n",
        "        self.downsample = downsample \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "id": "directed-terry",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amazing-jones"
      },
      "source": [
        "class bottleneck_block(nn.Module):\n",
        "    # 輸出通道乘的倍數\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride, downsample):\n",
        "        super(bottleneck_block, self).__init__()      \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        # 在 shortcut 時，若維度不一樣，要更改維度\n",
        "        self.downsample = downsample \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "id": "amazing-jones",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "charged-exposure"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, net_block, layers, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpooling = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.net_block_layer(net_block, 64, layers[0])\n",
        "        self.layer2 = self.net_block_layer(net_block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self.net_block_layer(net_block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self.net_block_layer(net_block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpooling = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * net_block.expansion, num_classes)\n",
        "\n",
        "        # 參數初始化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)        \n",
        "\n",
        "    def net_block_layer(self, net_block, out_channels, num_blocks, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "      # 在 shortcut 時，若維度不一樣，要更改維度\n",
        "        if stride != 1 or self.in_channels != out_channels * net_block.expansion:\n",
        "            downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * net_block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                                       nn.BatchNorm2d(out_channels * net_block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(net_block(self.in_channels, out_channels, stride, downsample))\n",
        "        if net_block.expansion != 1:\n",
        "            self.in_channels = out_channels * net_block.expansion\n",
        "\n",
        "        else:\n",
        "            self.in_channels = out_channels\n",
        "\n",
        "        for i in range(1, num_blocks):\n",
        "            layers.append(net_block(self.in_channels, out_channels, 1, None))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpooling(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpooling(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "id": "charged-exposure",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alive-edmonton"
      },
      "source": [
        "def ResNet_n(num_layers):\n",
        "    if num_layers == 18:\n",
        "        # ResNet18\n",
        "        model = ResNet(basic_block, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "    elif num_layers == 34:\n",
        "        # ResNet34\n",
        "        model = ResNet(basic_block, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "    elif num_layers == 50:\n",
        "        # ResNet50\n",
        "        model = ResNet(bottleneck_block, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "    elif num_layers == 101:\n",
        "        # ResNet101\n",
        "        model = ResNet(bottleneck_block, [3, 4, 23, 3], num_classes)\n",
        "\n",
        "    elif num_layers == 152:\n",
        "        # ResNet152\n",
        "        model = ResNet(bottleneck_block, [3, 8, 36, 3], num_classes)\n",
        "\n",
        "    else:\n",
        "        print(\"error\")\n",
        "\n",
        "        return\n",
        "\n",
        "    return model"
      ],
      "id": "alive-edmonton",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovely-ultimate"
      },
      "source": [
        "# Parameters\n",
        "batch_size = 64\n",
        "num_epochs = 15\n",
        "lr = 0.001\n",
        "\n",
        "num_classes=97\n",
        "\n",
        "# ResNet34\n",
        "model = ResNet_n(152)\n",
        "\n",
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "id": "lovely-ultimate",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organizational-skill"
      },
      "source": [
        "# Transform\n",
        "transform = transforms.Compose(\n",
        "                [transforms.Resize(size=(227,227)),\n",
        "                 transforms.CenterCrop(224),\n",
        "                 transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,), (0.5,)),]\n",
        "                )\n",
        "\n",
        "# Data\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/training/train', transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/training/valid', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "id": "organizational-skill",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "polar-bahrain"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target) \n",
        "        \n",
        "        if CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        # clear gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        output = model(data) \n",
        "        loss = criterion(output, target) \n",
        "\n",
        "        # Calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted = torch.max(output.data, 1)[1]\n",
        "        total_train += len(target)\n",
        "        correct_train += sum((predicted == target).float())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\"Train Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
        "               epoch+1, num_epochs, batch_idx+1, len(train_loader),\n",
        "               correct_train / float((batch_idx + 1) * batch_size),\n",
        "               train_loss / float((batch_idx + 1) * batch_size)))\n",
        "            \n",
        "    train_acc_ = 100 * (correct_train / float(total_train))\n",
        "    train_loss_ = train_loss / total_train\n",
        "                    \n",
        "    return train_acc_, train_loss_"
      ],
      "id": "polar-bahrain",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-stylus"
      },
      "source": [
        "def validate(valid_loader, model, criterion, epoch): \n",
        "    model.eval()\n",
        "    total_valid = 0\n",
        "    correct_valid = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        data, target = Variable(data), Variable(target) \n",
        "        \n",
        "        if CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target) \n",
        "\n",
        "        predicted = torch.max(output.data, 1)[1]\n",
        "        total_valid += len(target)\n",
        "        correct_valid += sum((predicted == target).float())\n",
        "        valid_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\"Valid Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
        "                epoch+1, num_epochs, batch_idx+1, len(valid_loader),\n",
        "                correct_valid / float((batch_idx + 1) * batch_size),\n",
        "                valid_loss / float((batch_idx + 1) * batch_size)))\n",
        "            \n",
        "    valid_acc_ = 100 * (correct_valid / float(total_valid))\n",
        "    valid_loss_ = valid_loss / total_valid\n",
        "                    \n",
        "    return valid_acc_, valid_loss_"
      ],
      "id": "anonymous-stylus",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "variable-isaac"
      },
      "source": [
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader):\n",
        "    # set objects for storing metrics\n",
        "    total_train_loss = []\n",
        "    total_valid_loss = []\n",
        "    total_train_accuracy = []\n",
        "    total_valid_accuracy = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(num_epochs):\n",
        "        # training\n",
        "        train_acc_, train_loss_ = train(train_loader, model, criterion, optimizer, epoch)\n",
        "        total_train_loss.append(train_loss_)\n",
        "        total_train_accuracy.append(train_acc_)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            valid_acc_, valid_loss_ = validate(valid_loader, model, criterion, epoch)\n",
        "            total_valid_loss.append(valid_loss_)\n",
        "            total_valid_accuracy.append(valid_acc_)\n",
        "\n",
        "        print('==========================================================================')\n",
        "        print(\"Epoch: {}/{}， Train acc： {:.6f}， Train loss： {:.6f}， Valid acc： {:.6f}， Valid loss： {:.6f}\".format(\n",
        "               epoch+1, num_epochs, \n",
        "               train_acc_, train_loss_,\n",
        "               valid_acc_, valid_loss_))\n",
        "        print('==========================================================================')\n",
        "\n",
        "    print(\"====== END ==========\")\n",
        "\n",
        "    return total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy"
      ],
      "id": "variable-isaac",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foreign-brother",
        "outputId": "4e4ac1ac-ff7c-4691-efb2-2c2896139250"
      },
      "source": [
        "total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy = training_loop(model, criterion, optimizer, train_loader, valid_loader)\n",
        "# random300"
      ],
      "id": "foreign-brother",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1/15 [iter： 1/145], acc： 0.046875, loss： 0.075294\n",
            "Train Epoch: 1/15 [iter： 101/145], acc： 0.009437, loss： 0.075055\n",
            "Valid Epoch: 1/15 [iter： 1/29], acc： 0.000000, loss： 0.070248\n",
            "==========================================================================\n",
            "Epoch: 1/15， Train acc： 1.208199， Train loss： 0.073845， Valid acc： 1.709873， Valid loss： 0.074962\n",
            "==========================================================================\n",
            "Train Epoch: 2/15 [iter： 1/145], acc： 0.015625, loss： 0.070050\n",
            "Train Epoch: 2/15 [iter： 101/145], acc： 0.025990, loss： 0.066454\n",
            "Valid Epoch: 2/15 [iter： 1/29], acc： 0.062500, loss： 0.044522\n",
            "==========================================================================\n",
            "Epoch: 2/15， Train acc： 2.837109， Train loss： 0.065447， Valid acc： 4.412576， Valid loss： 0.062336\n",
            "==========================================================================\n",
            "Train Epoch: 3/15 [iter： 1/145], acc： 0.046875, loss： 0.063284\n",
            "Train Epoch: 3/15 [iter： 101/145], acc： 0.064666, loss： 0.058911\n",
            "Valid Epoch: 3/15 [iter： 1/29], acc： 0.109375, loss： 0.059243\n",
            "==========================================================================\n",
            "Epoch: 3/15， Train acc： 8.317152， Train loss： 0.056568， Valid acc： 13.017098， Valid loss： 0.054464\n",
            "==========================================================================\n",
            "Train Epoch: 4/15 [iter： 1/145], acc： 0.109375, loss： 0.048229\n",
            "Train Epoch: 4/15 [iter： 101/145], acc： 0.215965, loss： 0.044355\n",
            "Valid Epoch: 4/15 [iter： 1/29], acc： 0.468750, loss： 0.023222\n",
            "==========================================================================\n",
            "Epoch: 4/15， Train acc： 24.498383， Train loss： 0.042439， Valid acc： 22.890236， Valid loss： 0.048173\n",
            "==========================================================================\n",
            "Train Epoch: 5/15 [iter： 1/145], acc： 0.218750, loss： 0.043627\n",
            "Train Epoch: 5/15 [iter： 101/145], acc： 0.405476, loss： 0.032945\n",
            "Valid Epoch: 5/15 [iter： 1/29], acc： 0.812500, loss： 0.010543\n",
            "==========================================================================\n",
            "Epoch: 5/15， Train acc： 43.980583， Train loss： 0.031156， Valid acc： 53.833424， Valid loss： 0.025903\n",
            "==========================================================================\n",
            "Train Epoch: 6/15 [iter： 1/145], acc： 0.593750, loss： 0.022406\n",
            "Train Epoch: 6/15 [iter： 101/145], acc： 0.617420, loss： 0.021235\n",
            "Valid Epoch: 6/15 [iter： 1/29], acc： 0.890625, loss： 0.005658\n",
            "==========================================================================\n",
            "Epoch: 6/15， Train acc： 62.675297， Train loss： 0.020526， Valid acc： 56.260342， Valid loss： 0.025854\n",
            "==========================================================================\n",
            "Train Epoch: 7/15 [iter： 1/145], acc： 0.765625, loss： 0.014275\n",
            "Train Epoch: 7/15 [iter： 101/145], acc： 0.741491, loss： 0.014127\n",
            "Valid Epoch: 7/15 [iter： 1/29], acc： 0.812500, loss： 0.011928\n",
            "==========================================================================\n",
            "Epoch: 7/15， Train acc： 75.329018， Train loss： 0.013532， Valid acc： 74.076118， Valid loss： 0.015314\n",
            "==========================================================================\n",
            "Train Epoch: 8/15 [iter： 1/145], acc： 0.843750, loss： 0.008142\n",
            "Train Epoch: 8/15 [iter： 101/145], acc： 0.816522, loss： 0.010248\n",
            "Valid Epoch: 8/15 [iter： 1/29], acc： 0.953125, loss： 0.003244\n",
            "==========================================================================\n",
            "Epoch: 8/15， Train acc： 81.823090， Train loss： 0.010003， Valid acc： 74.572525， Valid loss： 0.014619\n",
            "==========================================================================\n",
            "Train Epoch: 9/15 [iter： 1/145], acc： 0.937500, loss： 0.005350\n",
            "Train Epoch: 9/15 [iter： 101/145], acc： 0.860148, loss： 0.007607\n",
            "Valid Epoch: 9/15 [iter： 1/29], acc： 0.984375, loss： 0.001879\n",
            "==========================================================================\n",
            "Epoch: 9/15， Train acc： 85.911545， Train loss： 0.007670， Valid acc： 69.884171， Valid loss： 0.019437\n",
            "==========================================================================\n",
            "Train Epoch: 10/15 [iter： 1/145], acc： 0.937500, loss： 0.004224\n",
            "Train Epoch: 10/15 [iter： 101/145], acc： 0.899134, loss： 0.005338\n",
            "Valid Epoch: 10/15 [iter： 1/29], acc： 0.921875, loss： 0.004114\n",
            "==========================================================================\n",
            "Epoch: 10/15， Train acc： 89.568504， Train loss： 0.005606， Valid acc： 72.255928， Valid loss： 0.017497\n",
            "==========================================================================\n",
            "Train Epoch: 11/15 [iter： 1/145], acc： 0.921875, loss： 0.003964\n",
            "Train Epoch: 11/15 [iter： 101/145], acc： 0.923731, loss： 0.004104\n",
            "Valid Epoch: 11/15 [iter： 1/29], acc： 0.968750, loss： 0.001752\n",
            "==========================================================================\n",
            "Epoch: 11/15， Train acc： 92.038841， Train loss： 0.004205， Valid acc： 84.500824， Valid loss： 0.009681\n",
            "==========================================================================\n",
            "Train Epoch: 12/15 [iter： 1/145], acc： 0.968750, loss： 0.001732\n",
            "Train Epoch: 12/15 [iter： 101/145], acc： 0.949876, loss： 0.002780\n",
            "Valid Epoch: 12/15 [iter： 1/29], acc： 0.984375, loss： 0.001539\n",
            "==========================================================================\n",
            "Epoch: 12/15， Train acc： 94.185547， Train loss： 0.003168， Valid acc： 80.805290， Valid loss： 0.012797\n",
            "==========================================================================\n",
            "Train Epoch: 13/15 [iter： 1/145], acc： 0.921875, loss： 0.004672\n",
            "Train Epoch: 13/15 [iter： 101/145], acc： 0.946163, loss： 0.002755\n",
            "Valid Epoch: 13/15 [iter： 1/29], acc： 1.000000, loss： 0.000504\n",
            "==========================================================================\n",
            "Epoch: 13/15， Train acc： 94.692558， Train loss： 0.002749， Valid acc： 83.507988， Valid loss： 0.011038\n",
            "==========================================================================\n",
            "Train Epoch: 14/15 [iter： 1/145], acc： 0.984375, loss： 0.001456\n",
            "Train Epoch: 14/15 [iter： 101/145], acc： 0.958540, loss： 0.002222\n",
            "Valid Epoch: 14/15 [iter： 1/29], acc： 0.921875, loss： 0.004986\n",
            "==========================================================================\n",
            "Epoch: 14/15， Train acc： 95.318237， Train loss： 0.002463， Valid acc： 78.323212， Valid loss： 0.015652\n",
            "==========================================================================\n",
            "Train Epoch: 15/15 [iter： 1/145], acc： 0.953125, loss： 0.001846\n",
            "Train Epoch: 15/15 [iter： 101/145], acc： 0.939975, loss： 0.003042\n",
            "Valid Epoch: 15/15 [iter： 1/29], acc： 0.921875, loss： 0.003503\n",
            "==========================================================================\n",
            "Epoch: 15/15， Train acc： 94.077667， Train loss： 0.002995， Valid acc： 82.294533， Valid loss： 0.012137\n",
            "==========================================================================\n",
            "====== END ==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "matched-chest"
      },
      "source": [
        "from PIL import Image\n",
        "img= Image.open('/content/drive/MyDrive/TestData/10940_三.jpg')\n",
        "img=transform(img)\n",
        "img=torch.unsqueeze(img, dim=0).to(device)"
      ],
      "id": "matched-chest",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "according-institute",
        "outputId": "c66a6ad0-20c9-4132-f9a3-5212d6c709aa"
      },
      "source": [
        "ResNet_152(img).arfmax()"
      ],
      "id": "according-institute",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a4a9e32b3d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mResNet_152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marfmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ResNet_152' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWGGXspc-geP"
      },
      "source": [
        "if model(img).argmax()==三:\n",
        "  print(\"bingo\")\n",
        "else:\n",
        "  print(\"sad wrong\")"
      ],
      "id": "rWGGXspc-geP",
      "execution_count": null,
      "outputs": []
    }
  ]
}